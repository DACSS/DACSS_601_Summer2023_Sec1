---
title: "Challenge 3 "
author: "Zhongyue Lin"
description: "Tidy Data: Pivoting"
date: "6/7/2023"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  - challenge_3
  - animal_weights
  - eggs
  - australian_marriage
  - usa_households
  - sce_labor
---

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(readxl)

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

Today's challenge is to:

1.  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)
2.  identify what needs to be done to tidy the current data
3.  anticipate the shape of pivoted data
4.  pivot the data into tidy format using `pivot_longer`

## Read in data
-   USA Households\*.xlsx ⭐⭐⭐⭐


```{r}
# List all files in the "_data" directory that start with "USA Households"
files <- list.files(path = "_data", pattern = "USA Households.*\\.xlsx$", full.names = TRUE)

# Read each file, skip the first six lines, and save the results to a list
data_list <- lapply(files, function(x) read_excel(x, skip = 6))

# Use the bind_rows function to merge all the data boxes in the list into one data box
data_combined <- bind_rows(data_list)
# Rename the columns of the table according to the format of the original data
colnames(data_combined) <-  c(
  "Race and Hispanic origin of householder and year", 
  "Number (thousands)", 
  "Percent distribution Total", 
  "Percent distribution Under $15,000", 
  "Percent distribution $15,000 to $24,999", 
  "Percent distribution $25,000 to $34,999", 
  "Percent distribution $35,000 to $49,999", 
  "Percent distribution $50,000 to $74,999", 
  "Percent distribution $75,000 to $99,999", 
  "Percent distribution $100,000 to $149,999", 
  "Percent distribution $150,000 to $199,999", 
  "Percent distribution $200,000 and over", 
  "Median income (dollars) Estimate", 
  "Median income (dollars) Margin of error1 (±)", 
  "Mean income (dollars) Estimate", 
  "Mean income (dollars) Margin of error1 (±)"
)

# Print out the merged data
print(data_combined)
```
In dealing with the issue of complex table headers,I first identified the problem of the double-layered headers, which is not easy to handle directly in R. I proposed two potential solutions: simplifying the headers or storing data in a list, and decided to pursue the simplification approach. To do this, I designed new column names, integrating "Percent distribution" into each income bracket and adding **"Median income (dollars)"** and **"Mean income (dollars)"** into the respective **Estimate** and **Margin of error1 (±)** fields. Finally, I applied these new column names to the data frame using the `colnames()` function. Throughout this process, they demonstrated a clear and logical approach, ensuring the retention of all original data information while adapting the data structure to be more compatible with R's handling capabilities.

```{r}
#Remove text comments from the original table
data_clean <- head(data_combined, nrow(data_combined) - 31)
data_clean
```
```{r}
# Clear numeric comments in columns
data_clean$`Race and Hispanic origin of householder and year` <- gsub("\\s.*", "", data_clean$`Race and Hispanic origin of householder and year`)

data_clean
```

```{r}
# Get the column name of the original data frame
original_colnames <- colnames(data_clean)

# Create a new row with column names that exactly match the column names of the original data frame
new_row <- data.frame(t(rep("/", length(original_colnames))))
colnames(new_row) <- original_colnames

# Fill the value of the new line
new_row[1, "Race and Hispanic origin of householder and year"] <- "ALL RACE"

# Bind the new row to the original data frame
data_clean <- rbind(new_row, data_clean)
data_clean
# Find all the NA values in the data box and replace them with "/"
data_clean[is.na(data_clean)] <- "/"
data_clean
```

```{r}
# Find rows of non-year data
non_year_rows <- data_clean[!grepl("^\\d{4}$", data_clean$`Race and Hispanic origin of householder and year`), ]
non_year_rows
```

```{r}
# Define the value to replace
replacement_values <- c("WHITE ALONE", "WHITE", "WHITE ALONE, NOT HISPANIC", 
                        "WHITE, NOT HISPANIC", "BLACK ALONE OR IN COMBINATION",
                        "BLACK ALONE", "BLACK", "ASIAN ALONE OR IN COMBINATION",
                        "ASIAN ALONE", "ASIAN AND PACIFIC ISLANDER", "HISPANIC (ANY RACE)")

# Define the line to be replaced
replacement_rows <- c(56, 77, 113, 134, 165, 186, 207, 243, 264,285, 301)

# Replace the value in the `Race and Hispanic origin of householder and year` specified line
data_clean$`Race and Hispanic origin of householder and year`[replacement_rows] <- replacement_values

# View the updated data box
print(data_clean)



```


### Briefly describe the data

Describe the data, and be sure to comment on why you are planning to pivot it to make it "tidy"

## Anticipate the End Result

The first step in pivoting the data is to try to come up with a concrete vision of what the end product *should* look like - that way you will know whether or not your pivoting was successful.

One easy way to do this is to think about the dimensions of your current data (tibble, dataframe, or matrix), and then calculate what the dimensions of the pivoted data should be.

Suppose you have a dataset with $n$ rows and $k$ variables. In our example, 3 of the variables are used to identify a case, so you will be pivoting $k-3$ variables into a longer format where the $k-3$ variable names will move into the `names_to` variable and the current values in each of those columns will move into the `values_to` variable. Therefore, we would expect $n * (k-3)$ rows in the pivoted dataframe!

### Example: find current and future data dimensions

Lets see if this works with a simple example.

```{r}
#| tbl-cap: Example

df<-tibble(country = rep(c("Mexico", "USA", "France"),2),
           year = rep(c(1980,1990), 3), 
           trade = rep(c("NAFTA", "NAFTA", "EU"),2),
           outgoing = rnorm(6, mean=1000, sd=500),
           incoming = rlogis(6, location=1000, 
                             scale = 400))
df

#existing rows/cases
nrow(df)

#existing columns/cases
ncol(df)

#expected rows/cases
nrow(df) * (ncol(df)-3)

# expected columns 
3 + 2
```

Or simple example has $n = 6$ rows and $k - 3 = 2$ variables being pivoted, so we expect a new dataframe to have $n * 2 = 12$ rows x $3 + 2 = 5$ columns.

### Challenge: Describe the final dimensions

Document your work here.

```{r}


```

Any additional comments?

## Pivot the Data

Now we will pivot the data, and compare our pivoted data dimensions to the dimensions calculated above as a "sanity" check.

### Example

```{r}
#| tbl-cap: Pivoted Example

df<-pivot_longer(df, col = c(outgoing, incoming),
                 names_to="trade_direction",
                 values_to = "trade_value")
df
```

Yes, once it is pivoted long, our resulting data are $12x5$ - exactly what we expected!

### Challenge: Pivot the Chosen Data

Document your work here. What will a new "case" be once you have pivoted the data? How does it meet requirements for tidy data?

```{r}


```

Any additional comments?
